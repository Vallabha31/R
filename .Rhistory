library(factoextra)
install.packages("factoextra")
install.packages("factoextra")
install.packages("factoextra")
library(factoextra)
package_version()
install.packages("factoextra")
library(factoextra)
iris
data_omit <- na.omit(iris)
data_omit
data_omit_scale <- scale(data_omit)
data_omit_scale <- scale("data_omit")
data_omit_scale
data_omit_scale <- scale(,data_omit)
data_omit_scale <- scale(data_omit,)
data_omit_scale <- scale(1,data_omit)
data_omit_scale <- scale(1)
data_omit_scale
data_omit_scale <- scale(5)
data_omit_scale
data_subset <- data_omit_scale[1:5]
data_subset
fviz_nbclust(data_subset,kmeans(),method = "wss")+labs(subtitle = "Elbow Method")
# Load necessary libraries
install.packages(c("dplyr", "ggplot2"))
library(dplyr)
library(ggplot2)
# Load training dataset
train_data <- read.csv("myCarTrainDataset.csv")
train_data <- read.csv("myCarTrainDataset_2023.csv")
train_data <- read.csv("myCarTrainDataset_2023.csv")
train_data <- read.csv("myCarTrainDataset_2023.csv")
setwd("C:/tmp/datamining")
getwd
getwd()
# Load necessary libraries
install.packages(c("dplyr", "ggplot2"))
library(dplyr)
library(ggplot2)
# Load training dataset
train_data <- read.csv("myCarTrainDataset.csv")
install.packages(c("dplyr", "ggplot2"))
# Load necessary libraries
install.packages(c("dplyr", "ggplot2"))
library(dplyr)
library(ggplot2)
# Load training dataset
train_data <- read.csv("myCarTrainDataset_2023.csv")
# Summary statistics
summary(train_data)
# Visualize the distribution of acceptance
ggplot(train_data, aes(x = acceptance)) +
geom_bar(fill = "steelblue") +
labs(title = "Distribution of Car Acceptance")
install.packages(c("dplyr", "ggplot2"))
install.packages(c("dplyr", "ggplot2"))
install.packages(c("dplyr", "ggplot2"))
install.packages(c("dplyr", "ggplot2"))
# Load necessary libraries
install.packages(c("rpart", "rpart.plot"))
library(rpart)
library(rpart.plot)
# Convert categorical variables to factors
train_data$buying <- as.factor(train_data$buying)
train_data$maint <- as.factor(train_data$maint)
train_data$persons <- as.factor(train_data$persons)
train_data$safety <- as.factor(train_data$safety)
train_data$acceptance <- as.factor(train_data$acceptance)
# Build the decision tree
tree_model <- rpart(acceptance ~ buying + maint + persons + safety, data = train_data, method = "class", parms = list(split = "gini"))
# Plot the decision tree
rpart.plot(tree_model)
# Load necessary libraries
install.packages("rpart.plot")
library(rpart.plot)
# Load test dataset
test_data <- read.csv("myCarTestDataset_2023.csv")
# Convert categorical variables to factors
test_data$buying <- as.factor(test_data$buying)
test_data$maint <- as.factor(test_data$maint)
test_data$persons <- as.factor(test_data$persons)
test_data$safety <- as.factor(test_data$safety)
test_data$acceptance <- as.factor(test_data$acceptance)
# Prune the tree
pruned_tree <- prune(tree_model, cp = 0.01)  # Adjust cp parameter as needed
# Plot pruned tree
rpart.plot(pruned_tree)
# Predict on the test set
predictions <- predict(pruned_tree, test_data, type = "class")
# Create confusion matrix
conf_matrix <- table(predictions, test_data$acceptance)
conf_matrix
install.packages("rpart.plot")
rpart.plot(pruned_tree)
install.packages("rpart.plot")
# Load necessary libraries
install.packages("rpart.plot")
library(rpart.plot)
# Load test dataset
test_data <- read.csv("myCarTestDataset_2023.csv")
# Convert categorical variables to factors
test_data$buying <- as.factor(test_data$buying)
test_data$maint <- as.factor(test_data$maint)
test_data$persons <- as.factor(test_data$persons)
test_data$safety <- as.factor(test_data$safety)
test_data$acceptance <- as.factor(test_data$acceptance)
# Prune the tree
pruned_tree <- prune(tree_model, cp = 0.01)  # Adjust cp parameter as needed
# Plot pruned tree
rpart.plot(pruned_tree)
# Predict on the test set
predictions <- predict(pruned_tree, test_data, type = "class")
# Create confusion matrix
conf_matrix <- table(predictions, test_data$acceptance)
conf_matrix
# Load necessary libraries
install.packages(c("rpart", "rpart.plot", "caret"))
library(rpart)
library(rpart.plot)
library(caret)
# Load necessary libraries
install.packages(c("rpart", "rpart.plot", "caret"))
library(rpart)
library(rpart.plot)
library(caret)
# Load training dataset
train_data <- read.csv("myCarTrainDataset_2023.csv")
# Convert categorical variables to factors
train_data$buying <- as.factor(train_data$buying)
train_data$maint <- as.factor(train_data$maint)
train_data$persons <- as.factor(train_data$persons)
train_data$safety <- as.factor(train_data$safety)
train_data$acceptance <- as.factor(train_data$acceptance)
# Create a data partition for cross-validation
set.seed(123)  # Set seed for reproducibility
index <- createDataPartition(train_data$acceptance, p = 0.8, list = FALSE)
# Split the data into training and validation sets
train_set <- train_data[index, ]
valid_set <- train_data[-index, ]
# Define hyperparameter grid
hyper_grid <- expand.grid(cp = seq(0.001, 0.1, by = 0.001))
# Perform cross-validated hyperparameter tuning
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation
cv_model <- train(
acceptance ~ buying + maint + persons + safety,
data = train_set,
method = "rpart",
tuneGrid = hyper_grid,
trControl = ctrl
)
# Get the best hyperparameters
best_cp <- cv_model$bestTune$cp
# Build the final model using the best hyperparameters
final_tree <- rpart(
acceptance ~ buying + maint + persons + safety,
data = train_data,
method = "class",
parms = list(split = "gini"),
control = rpart.control(cp = best_cp)
)
# Plot the final decision tree
rpart.plot(final_tree)
install.packages(c("rpart", "rpart.plot", "caret"))
# Create a hypothetical dataset
data <- data.frame(
feature = c(1, 2, 3, 4, 5),
target = c("unacc", "acc", "unacc", "acc", "unacc")
)
# Function to calculate Gini index
calculateGiniIndex <- function(target) {
proportions <- table(target) / length(target)
gini <- 1 - sum(proportions^2)
return(gini)
}
# Function to calculate Gini impurity for a split
calculateGiniImpurity <- function(data, feature, threshold) {
node1 <- data[data[[feature]] <= threshold, ]
node2 <- data[data[[feature]] > threshold, ]
n1 <- nrow(node1)
n2 <- nrow(node2)
n <- nrow(data)
gini_split <- (n1/n) * calculateGiniIndex(node1$target) + (n2/n) * calculateGiniIndex(node2$target)
return(gini_split)
}
# Example usage
gini_index <- calculateGiniIndex(data$target)
gini_impurity <- calculateGiniImpurity(data, "feature", 3)
print(paste("Gini Index:", gini_index))
print(paste("Gini Impurity for Split:", gini_impurity))
# Assuming your dataset looks like this (replace with your actual column names):
# myCarTrainDataset <- read.csv("path/to/myCarTrainDataset.csv")
# Function to calculate Gini index
calculateGiniIndex <- function(target) {
proportions <- table(target) / length(target)
gini <- 1 - sum(proportions^2)
return(gini)
}
# Function to calculate Gini impurity for a split
calculateGiniImpurity <- function(data, feature, threshold) {
node1 <- data[data[[feature]] <= threshold, ]
node2 <- data[data[[feature]] > threshold, ]
n1 <- nrow(node1)
n2 <- nrow(node2)
n <- nrow(data)
gini_split <- (n1/n) * calculateGiniIndex(node1$acceptance) + (n2/n) * calculateGiniIndex(node2$acceptance)
return(gini_split)
}
# Example usage
# Replace "feature" with the actual feature name in your dataset and adjust the threshold accordingly
gini_index <- calculateGiniIndex(train_data$acceptance)
gini_impurity <- calculateGiniImpurity(train_data, "feature", 3)
print(paste("Gini Index:", gini_index))
print(paste("Gini Impurity for Split:", gini_impurity))
root_gini <- 1 - sum((table(train_data$acceptance) / nrow(train_data))^2)
attributes <- names(train_data)[1:(ncol(train_data)-1)]
gini_gains <- numeric(length(attributes))
splits <- list()
for (attribute in attributes) {
unique_values <- unique(train_data[[attribute]])
gini_splits <- numeric(length(unique_values))
for (value in unique_values) {
gini_splits[value] <- calculateGiniImpurity(train_data, attribute, value)
}
weighted_gini <- sum(table(train_data[[attribute]]) / nrow(train_data) * gini_splits)
gini_gain <- root_gini - weighted_gini
gini_gains[attribute] <- gini_gain
splits[[attribute]] <- list(values = unique_values, gini = gini_splits)
}
setwd("C:/tmp/datamining")
getwd()
train_data <- read.csv("myCarTrainDataset_2023.csv")
str(train_data)
summary(train_data)
table(train_data$acceptance)
table(train_data$buying)
table(train_data$maint)
table(train_data$persons)
table(train_data$safety)
calculateGiniImpurity(train_data)
calculateGiniImpurity <- function(train_data, attendance, unacc) {
left_subset <- train_data[train_data[["persons"]] == 2, ]
right_subset <- train_data[train_data[["persons"]] != 2, ]
gini_left <- 1 - sum((table(left_subset$acceptance) / nrow(left_subset))^2)
gini_right <- 1 - sum((table(right_subset$acceptance) / nrow(right_subset))^2)
gini_impurity <- (nrow(left_subset) / nrow(train_data)) * gini_left + (nrow(right_subset) / nrow(train_data)) * gini_right
return(gini_impurity)
}
calculateGiniImpurity <- function(data, feature, threshold) {
left_subset <- data[data[[feature]] == threshold, ]
right_subset <- data[data[[feature]] != threshold, ]
gini_left <- 1 - sum((table(left_subset$acceptance) / nrow(left_subset))^2)
gini_right <- 1 - sum((table(right_subset$acceptance) / nrow(right_subset))^2)
gini_impurity <- (nrow(left_subset) / nrow(data)) * gini_left + (nrow(right_subset) / nrow(data)) * gini_right
return(gini_impurity)
}
load("C:/tmp/datamining/.RData")
var(train_data$persons)
sd(train_data$persons)
var(train_data$persons)
sd(train_data)
var(train_data)
sd(train_data$persons)
View(valid_set)
View(test_data)
View(pruned_tree)
pruned_tree[["call"]]
View(test_data)
# Assuming 'test_data' is your data frame
conf_matrix <- table(test_data$acceptance, test_data$predictions)
View(best_split)
View(final_tree)
View(hyper_grid)
best_split[["impurity"]]
View(test_data_dummies)
View(train_set)
View(tree_model)
View(tree_model)
View(valid_set)
# Create a hypothetical dataset
data <- data.frame(
feature = c(1, 2, 3, 4, 5),
target = c("unacc", "acc", "unacc", "acc", "unacc")
)
predictions <- predict(pruned_tree, test_data, type = "class")
conf_matrix <- table(predictions, test_data$acceptance)
conf_matrix
# Assuming car_train_data is your dataset
# Assuming 'acceptance' is the column containing acceptance values
# Count the occurrences of each acceptance level
acceptance_counts <- table(train_data$acceptance)
# Create a bar plot
barplot(acceptance_counts,
main = "Distribution of Car Acceptance",
xlab = "Acceptance Level",
ylab = "Frequency",
col = "skyblue",  # Set the color of the bars
border = "black",  # Set the color of the bar borders
names.arg = c("Unacceptable", "Acceptable", "Good", "Very Good"))  # Specify labels for each bar
# Assuming car_train_data is your dataset
# Assuming 'acceptance' is the column containing acceptance values
# Count the occurrences of each acceptance level
acceptance_counts <- table(train_data$acceptance)
# Create a bar plot
barplot(acceptance_counts,
main = "Car Acceptance",
xlab = "Acceptance Level",
ylab = "Frequency",
col = "skyblue",  # Set the color of the bars
border = "black",  # Set the color of the bar borders
names.arg = c("Unacceptable", "Acceptable", "Good", "Very Good"))  # Specify labels for each bar
# Assuming car_train_data is your dataset
# Assuming 'acceptance' is the column containing acceptance values
# Count the occurrences of each acceptance level
acceptance_counts <- table(train_data$acceptance)
# Create a bar plot
barplot(acceptance_counts,
main = "Car Acceptance",
xlab = "Acceptance Level",
ylab = "Frequency",
col = "skyblue",  # Set the color of the bars
border = "black",  # Set the color of the bar borders
names.arg = c("Unacc", "Acc"))  # Specify labels for each bar
# Assuming car_train_data is your dataset
# Assuming 'acceptance' is the column containing acceptance values
# Count the occurrences of each acceptance level
acceptance_counts <- table(train_data$acceptance)
# Create a bar plot
barplot(acceptance_counts,
main = "Distribution of Car Acceptance",
xlab = "Acceptance Level",
ylab = "Frequency",
col = "skyblue","red",  # Set the color of the bars
border = "black",  # Set the color of the bar borders
names.arg = c("Unacc", "Acc"))  # Specify labels for each bar
# Assuming car_train_data is your dataset
# Assuming 'acceptance' is the column containing acceptance values
# Count the occurrences of each acceptance level
acceptance_counts <- table(train_data$acceptance)
# Create a bar plot
barplot(acceptance_counts,
main = "Car Acceptance",
xlab = "Acceptance Level",
ylab = "Frequency",
col = c("skyblue","red"),  # Set the color of the bars
border = "black",  # Set the color of the bar borders
names.arg = c("Unacc", "Acc"))  # Specify labels for each bar
# Assuming car_train_data is your dataset
# Assuming 'acceptance' is the column containing acceptance values
# Count the occurrences of each acceptance level
acceptance_counts <- table(train_data$acceptance)
# Create a bar plot
barplot(acceptance_counts,
main = "Distribution of Car Acceptance",
xlab = "Acceptance Level",
ylab = "Frequency",
col = c("skyblue","red"),  # Set the color of the bars
border = "black",  # Set the color of the bar borders
names.arg = c("Unacc", "Acc"))  # Specify labels for each bar
